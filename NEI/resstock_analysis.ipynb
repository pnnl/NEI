{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # built-in functions for working with the Windows system\n",
    "import pandas as pd # most popular data science library for working with panel/tabular data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path for users\n",
    "username = os.getlogin()\n",
    "if username == \"root\":\n",
    "    username = os.getenv(\"USER\")\n",
    "\n",
    "if username == \"rose775\":\n",
    "    path_2024_1 = \"/Users/rose775/Library/CloudStorage/OneDrive-PNNL/General - NEB Decarb/Datasets/ResStock/2024.1\"\n",
    "    path_2024_2 = \"/Users/rose775/Library/CloudStorage/OneDrive-PNNL/General - NEB Decarb/Datasets/ResStock/2024.2\"\n",
    "    path_out_2024_1 = \"/Users/rose775/Library/CloudStorage/OneDrive-PNNL/General - NEB Decarb/Analysis/resstock_results/2024_1\"\n",
    "    path_out_2024_2 = \"/Users/rose775/Library/CloudStorage/OneDrive-PNNL/General - NEB Decarb/Analysis/resstock_results/2024_2\"\n",
    "\n",
    "elif username == \"kieren_username\":\n",
    "    path_2024_1 = \"/General - NEB Decarb/Datasets/ResStock/2024.1\"\n",
    "    path_2024_2 = \"/General - NEB Decarb/Datasets/ResStock/2024.2\"\n",
    "    path_out_2024_1 = \"/General - NEB Decarb/Analysis/resstock_results/2024_1\"\n",
    "    path_out_2024_2 = \"/General - NEB Decarb/Analysis/resstock_results/2024_2\"\n",
    "\n",
    "elif username == \"max_username\":\n",
    "    path_2024_1 = \"/General - NEB Decarb/Datasets/ResStock/2024.1\"\n",
    "    path_2024_2 = \"/General - NEB Decarb/Datasets/ResStock/2024.2\"\n",
    "    path_out_2024_1 = \"/General - NEB Decarb/Analysis/resstock_results/2024_1\"\n",
    "    path_out_2024_2 = \"/General - NEB Decarb/Analysis/resstock_results/2024_2\"\n",
    "\n",
    "else:\n",
    "    print(\"Who are you and why are you doing ResStock analysis?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_2024_1 = [\"baseline_metadata_and_annual_results.parquet\", \"upgrade2.01_metadata_and_annual_results.parquet\", \"upgrade2.02_metadata_and_annual_results.parquet\",\n",
    "                \"upgrade3.03_metadata_and_annual_results.parquet\", \"upgrade3.07_metadata_and_annual_results.parquet\"]\n",
    "\n",
    "files_2024_2 = [\"baseline_metadata_and_annual_results.parquet\", \"upgrade01_metadata_and_annual_results.parquet\", \"upgrade02_metadata_and_annual_results.parquet\",\n",
    "                \"upgrade03_metadata_and_annual_results.parquet\", \"upgrade04_metadata_and_annual_results.parquet\", \"upgrade05_metadata_and_annual_results.parquet\",\n",
    "                \"upgrade06_metadata_and_annual_results.parquet\", \"upgrade07_metadata_and_annual_results.parquet\", \"upgrade08_metadata_and_annual_results.parquet\",\n",
    "                \"upgrade09_metadata_and_annual_results.parquet\", \"upgrade10_metadata_and_annual_results.parquet\", \"upgrade14_metadata_and_annual_results.parquet\",\n",
    "                \"upgrade15_metadata_and_annual_results.parquet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_resstock_files(files, path_in):\n",
    "    dfs = {} # create empty dictionary to fill with Pandas dataframes\n",
    "\n",
    "    # Loop through each file name, read the file, and store the df in dfs dictionary\n",
    "    if files is files_2024_1: # make sure we're reading files from 2024v1\n",
    "        for file in files:\n",
    "            x = file.split('_')[0] # just use the \"baseline\" or \"upgradeXX\" information for naming the dfs\n",
    "            df_name = f\"{x}_2024_1\"\n",
    "            dfs[df_name] = pd.read_parquet(f\"{path_in}/{file}\").reset_index() # read the parquet and save the named df to the dict\n",
    "    elif files is files_2024_2:\n",
    "        for file in files:\n",
    "            x = file.split('_')[0]\n",
    "            df_name = f\"{x}_2024_2\"\n",
    "            dfs[df_name] = pd.read_parquet(f\"{path_in}/{file}\").reset_index()\n",
    "\n",
    "    keys = list(dfs.keys())\n",
    "\n",
    "    return dfs, keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_resstock_dataframes(dfs, files):\n",
    "    new_dfs = {}\n",
    "\n",
    "    if files is files_2024_1: # have to separate v1 and v2 because out.emissions.all_fuels.etc is different between the two\n",
    "        for key, df in dfs.items():\n",
    "            new_df_name = key + \"_new\"\n",
    "            new_dfs[new_df_name] = pd.DataFrame(df.loc[:, \"bldg_id\":\"upgrade\"].join(df.loc[:, \"out.site_energy.net.energy_consumption.kwh\":\"out.emissions.all_fuels.lrmer_mid_case_2030_boxavg.co2e_kg\"]))\n",
    "        \n",
    "        new_keys = list(new_dfs.keys())\n",
    "\n",
    "    elif files is files_2024_2:\n",
    "        for key, df in dfs.items():\n",
    "            new_df_name = key + \"_new\"\n",
    "            new_dfs[new_df_name] = pd.DataFrame(df.loc[:, \"bldg_id\":\"upgrade\"].join(df.loc[:, \"out.site_energy.net.energy_consumption.kwh\":\"out.emissions.all_fuels.lrmer_mid_case_15.co2e_kg\"]))\n",
    "        \n",
    "        new_keys = list(new_dfs.keys())\n",
    "\n",
    "\n",
    "    return new_dfs, new_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resstock_analysis(new_dfs, baseline_new, df_metadata, path_out):\n",
    "    for key, df in new_dfs.items():\n",
    "        if key not in [\"baseline_2024_1_new\", \"baseline_2024_2_new\"]:\n",
    "            df = df.apply(pd.to_numeric, errors='coerce')\n",
    "            baseline_new = baseline_new.apply(pd.to_numeric, errors='coerce')\n",
    "            df_diff = df - baseline_new\n",
    "            df_full = pd.concat([df_metadata, df_diff], axis=1)\n",
    "\n",
    "            # Select numerical columns excluding the specific non-numerical or grouping column\n",
    "            numerical_cols = df_full.select_dtypes(include=np.number).columns.drop('in.ashrae_iecc_climate_zone_2004', errors='ignore')\n",
    "            df_averaged_cz = df_full.groupby('in.ashrae_iecc_climate_zone_2004')[numerical_cols].mean().reset_index()\n",
    "\n",
    "            keeper_cols = [\"in.ashrae_iecc_climate_zone_2004\", \"in.sqft\", \"out.site_energy.net.energy_consumption.kwh\",\n",
    "                                            \"out.emissions.all_fuels.lrmer_high_re_cost_2030_boxavg.co2e_kg\",\n",
    "                                            \"out.emissions.all_fuels.lrmer_low_re_cost_2030_boxavg.co2e_kg\",\n",
    "                                            \"out.emissions.all_fuels.lrmer_mid_case_2030_boxavg.co2e_kg\", \n",
    "                                            \"out.emissions.all_fuels.lrmer_high_re_cost_15.co2e_kg\",\n",
    "                                            \"out.emissions.all_fuels.lrmer_low_re_cost_15.co2e_kg\", \"out.emissions.all_fuels.lrmer_mid_case_15.co2e_kg\"]\n",
    "            df_averaged_cz = df_averaged_cz.loc[:, [col for col in keeper_cols if col in df_averaged_cz.columns]].round(0) # can be any of the columns in keeper_cols bc v1 and v2 are different\n",
    "\n",
    "            # to .csv\n",
    "            df_averaged_cz.to_csv(f\"{path_out}/{key}_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment/uncomment the block to be used for the run, no other modifications needed\n",
    "\n",
    "# files = files_2024_1\n",
    "# path_in = path_2024_1\n",
    "# path_out = path_out_2024_1\n",
    "\n",
    "files = files_2024_2\n",
    "path_in = path_2024_2\n",
    "path_out = path_out_2024_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs, keys = read_resstock_files(files, path_in=path_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dfs, new_keys = new_resstock_dataframes(dfs, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to hold some data out of the function for analysis\n",
    "if files is files_2024_1:\n",
    "    df_metadata = dfs[\"baseline_2024_1\"][['bldg_id', 'in.sqft', 'weight', 'in.ashrae_iecc_climate_zone_2004', 'in.census_division', 'in.census_region', 'in.county']]\n",
    "    baseline_new = new_dfs[\"baseline_2024_1_new\"]\n",
    "elif files is files_2024_2:\n",
    "    df_metadata = dfs[\"baseline_2024_2\"][['bldg_id', 'in.sqft', 'weight', 'in.ashrae_iecc_climate_zone_2004', 'in.census_division', 'in.census_region', 'in.county']]\n",
    "    baseline_new = new_dfs[\"baseline_2024_2_new\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resstock_analysis(new_dfs, baseline_new=baseline_new, df_metadata=df_metadata, path_out=path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
